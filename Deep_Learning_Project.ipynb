{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPBQ2Ebzi4H88kPSHBmArqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oojjww1/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code/blob/main/Deep_Learning_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyZKXwySUFi3"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t44EUkrUFlS"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFsVQzPLUUdN"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpX-cy0kUUfW"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JOcJ5PwUUmx"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4To_IzpbUh3j"
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vQDfXpdUh5y"
      },
      "source": [
        "! kaggle datasets download -d google/google-landmarks-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjXk1CnaVi5f"
      },
      "source": [
        "! unzip google-landmarks-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGWG8u0O03PO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from random import randint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import urllib\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1psbd7GO06iR"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4FO7rpq06kc"
      },
      "source": [
        "# load train data\n",
        "df_train = pd.read_csv('train.csv')\n",
        "print(df_train.head())\n",
        "\n",
        "# load boxes data and merge into one\n",
        "df_boxes_split1 = pd.read_csv('boxes_split1.csv')\n",
        "df_boxes_split2 = pd.read_csv('boxes_split2.csv')\n",
        "df_boxes = pd.concat([df_boxes_split1, df_boxes_split2])\n",
        "\n",
        "print(df_boxes.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqLklLf06mk"
      },
      "source": [
        "# merge train and boxes on id\n",
        "df_train = pd.merge(df_train, df_boxes, on='id',  how='right')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwe6TIDI06od"
      },
      "source": [
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    if train:\n",
        "        # random horizontal flip with 50% probability\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztkYJMeU06qL"
      },
      "source": [
        "class GoogleLandmarks(Dataset):\n",
        "    def __init__(self, df, transforms):\n",
        "        self.df = df\n",
        "        self.dim = (512, 512)\n",
        "        self.transforms = transforms\n",
        "        self.ids = np.unique(df['landmark_id'].values)\n",
        "        self.ids_dic = {v:k for k,v in enumerate(self.ids)}\n",
        "    \n",
        "    def url_to_image(self, url, dim):\n",
        "        try:\n",
        "            resp = urllib.request.urlopen(url)\n",
        "        except:\n",
        "            return np.array([])\n",
        "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "        if(image.size != 0):\n",
        "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "            image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
        "            image = Image.fromarray(np.uint8(image))\n",
        "            if(image):\n",
        "                image = self.transforms(image)\n",
        "        else:\n",
        "            image = Image.fromarray(image)\n",
        "        return T.ToTensor()(image)\n",
        "    \n",
        "    def get_rect(self, boxes):\n",
        "        try:\n",
        "            y = boxes[0]\n",
        "            x = boxes[1]\n",
        "            h = boxes[2] - boxes[0]\n",
        "            w = boxes[3] - boxes[1]\n",
        "        except:\n",
        "            return None\n",
        "        return plt.Rectangle((x, y), w, h, color='y', alpha=0.3)\n",
        "    \n",
        "    def draw_bbox(self, img, rect):\n",
        "        fig, ax = plt.subplots()\n",
        "        plt.imshow(img.permute(1, 2, 0))\n",
        "        if(rect):\n",
        "            ax.add_patch(rect)\n",
        "    \n",
        "    def format_boxes(self, boxes, dim):\n",
        "        return (np.array(boxes.split(' ')).astype(np.float32) * dim[0]).astype(np.int64)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        id = self.df.iloc[idx].id\n",
        "        landmarkid = self.df.iloc[idx].landmark_id\n",
        "        url = self.df[self.df.id == id].url.values[0]\n",
        "        boxes = self.df[self.df.id == id].box.values[0]\n",
        "        \n",
        "        \n",
        "        # format boxes\n",
        "        boxes = self.format_boxes(boxes, self.dim)\n",
        "        \n",
        "        labels = np.eye(len(self.ids))[self.ids_dic[landmarkid]]\n",
        "        \n",
        "        target = {}\n",
        "        target[\"boxes\"] = torch.as_tensor([boxes], dtype=torch.int64)\n",
        "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        target[\"image_id\"] = torch.tensor([idx])\n",
        "        target[\"area\"] = (boxes[3] - boxes[1]) * (boxes[2] - boxes[0])\n",
        "        target[\"iscrowd\"] = torch.zeros((1,), dtype=torch.int64)\n",
        "        \n",
        "        image = self.url_to_image(url, self.dim)\n",
        "        \n",
        "        if(len(image) == 0):\n",
        "            return None, None\n",
        "        \n",
        "        return image, target\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "# select 10 ids randomly\n",
        "idxes = [randint(0, len(df_train) - 1) for i in range(10)]\n",
        "\n",
        "# select only 10 landmarks\n",
        "ids_of_landmarks = df_train['landmark_id'][idxes].values\n",
        "\n",
        "# subset of training data with 10 landmarks\n",
        "df = df_train[df_train['landmark_id'].isin(ids_of_landmarks)]\n",
        "\n",
        "# google dataset\n",
        "google_ds = GoogleLandmarks(df, get_transform(train=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_aqDdm406sP"
      },
      "source": [
        "image, target = google_ds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkpES6d106t5"
      },
      "source": [
        "rect = google_ds.get_rect(target['boxes'][0])\n",
        "google_ds.draw_bbox(image, rect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wo9zWne06vc"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZHjIzUh06xX"
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(\n",
        "        google_ds, batch_size=8, shuffle=True, num_workers=4,\n",
        "        collate_fn=collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQug2HAWRL4"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvTgYN-HWROO"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "num_classes = 2\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIyIsCiCWRQI"
      },
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyOUXEApWRSw"
      },
      "source": [
        "total_errors = []\n",
        "for epoch in range(10):\n",
        "    losses_arr = []\n",
        "\n",
        "    for images, targets in data_loader:\n",
        "\n",
        "        images = list(image.to(device) for image in images if image is not None)\n",
        "        targets = [{k: torch.as_tensor(v).detach().to(device) for k, v in t.items()} for t in targets if t is not None]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        losses_arr.append(losses.item())\n",
        "\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update the learning rate\n",
        "        # lr_scheduler.step()\n",
        "        \n",
        "    total_errors.append(np.mean(np.array(losses_arr)))\n",
        "    if epoch % 1 == 0:\n",
        "        print(\"Epoch:{0:3d}, Loss:{1:1.3f}\".format(epoch, total_errors[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQaD_BCnWRUa"
      },
      "source": [
        "plt.plot(total_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDMjVIy806zP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcXwPJV061F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nugpyaQ062x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}